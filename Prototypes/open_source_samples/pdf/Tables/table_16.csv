,Unnamed: 0,Total train,Total train.1,Unnamed: 1,Unnamed: 2,Flops,Unnamed: 3,flops per,params active
0,,compute,compute,Params,Training tokens,per param,Mult for,active param,for each
1,Model,(PF-days),(flops),(M),(billions),per token,bwd pass,per token,token
2,T5-Small,2.08E+00,1.80E+20,60,"1,000",3,3,1,0.5
3,T5-Base,7.64E+00,6.60E+20,220,"1,000",3,3,1,0.5
4,T5-Large,2.67E+01,2.31E+21,770,"1,000",3,3,1,0.5
5,T5-3B,1.04E+02,9.00E+21,"3,000","1,000",3,3,1,0.5
6,T5-11B,3.82E+02,3.30E+22,"11,000","1,000",3,3,1,0.5
7,BERT-Base,1.89E+00,1.64E+20,109,250,6,3,2,1.0
8,BERT-Large,6.16E+00,5.33E+20,355,250,6,3,2,1.0
9,RoBERTa-Base,1.74E+01,1.50E+21,125,"2,000",6,3,2,1.0
10,RoBERTa-Large,4.93E+01,4.26E+21,355,"2,000",6,3,2,1.0
11,GPT-3 Small,2.60E+00,2.25E+20,125,300,6,3,2,1.0
12,GPT-3 Medium,7.42E+00,6.41E+20,356,300,6,3,2,1.0
13,GPT-3 Large,1.58E+01,1.37E+21,760,300,6,3,2,1.0
14,GPT-3 XL,2.75E+01,2.38E+21,"1,320",300,6,3,2,1.0
15,GPT-3 2.7B,5.52E+01,4.77E+21,"2,650",300,6,3,2,1.0
16,GPT-3 6.7B,1.39E+02,1.20E+22,"6,660",300,6,3,2,1.0
17,GPT-3 13B,2.68E+02,2.31E+22,"12,850",300,6,3,2,1.0
18,GPT-3 175B,3.64E+03,3.14E+23,"174,600",300,6,3,2,1.0
